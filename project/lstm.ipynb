{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "\n",
    "# Time\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tools\n",
    "import itertools\n",
    "from collections import Counter\n",
    "\n",
    "# NLP\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# from pywsd.utils import lemmatize_sentence\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight as cw\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "# Deep Learing Preprocessing - Keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Deep Learning Model - Keras\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "\n",
    "# Deep Learning Model - Keras - CNN\n",
    "from keras.layers import Conv1D, Conv2D, Convolution1D, MaxPooling1D, SeparableConv1D, SpatialDropout1D, \\\n",
    "    GlobalAvgPool1D, GlobalMaxPool1D, GlobalMaxPooling1D \n",
    "from keras.layers.pooling import _GlobalPooling1D\n",
    "from keras.layers import MaxPooling2D, GlobalMaxPooling2D, GlobalAveragePooling2D\n",
    "\n",
    "from keras.layers import MaxPooling3D, GlobalMaxPooling3D, GlobalAveragePooling3D\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning Model - Keras - RNN\n",
    "from keras.layers import Embedding, LSTM, Bidirectional\n",
    "\n",
    "# Deep Learning Model - Keras - General\n",
    "from keras.layers import Input, Add, concatenate, Dense, Activation, BatchNormalization, Dropout, Flatten\n",
    "from keras.layers import LeakyReLU, PReLU, Lambda, Multiply\n",
    "\n",
    "\n",
    "\n",
    "# Deep Learning Parameters - Keras\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "\n",
    "# Deep Learning Callbacs - Keras\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['train.tsv', 'test_samples.csv', 'train_preprocessed.csv']\n"
     ]
    }
   ],
   "source": [
    "print(os.listdir(\"input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading Data\n",
    "rev_frame = pd.read_csv(\"input/train_preprocessed.csv\")\n",
    "t_id = pd.read_csv(\"input/test_samples.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=rev_frame.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>gas by my house hit am going to chapel hill on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>theo walcott is still shit watch rafa and john...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>its not that am gsp fan just hate nick diaz ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>iranian general says israel iron dome cannot d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>tehran mon amour obama tried to establish ties...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                        clean_tweet sentiment\n",
       "0           0  gas by my house hit am going to chapel hill on...  positive\n",
       "1           1  theo walcott is still shit watch rafa and john...  negative\n",
       "2           2  its not that am gsp fan just hate nick diaz ca...  negative\n",
       "3           3  iranian general says israel iron dome cannot d...  negative\n",
       "4           4  tehran mon amour obama tried to establish ties...   neutral"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['clean_tweet','sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[:21629]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21629, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gas by my house hit am going to chapel hill on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>theo walcott is still shit watch rafa and john...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>its not that am gsp fan just hate nick diaz ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iranian general says israel iron dome cannot d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tehran mon amour obama tried to establish ties...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet sentiment\n",
       "0  gas by my house hit am going to chapel hill on...  positive\n",
       "1  theo walcott is still shit watch rafa and john...  negative\n",
       "2  its not that am gsp fan just hate nick diaz ca...  negative\n",
       "3  iranian general says israel iron dome cannot d...  negative\n",
       "4  tehran mon amour obama tried to establish ties...   neutral"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clean_tweet    0\n",
       "sentiment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check for null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gas by my house hit am going to chapel hill on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>theo walcott is still shit watch rafa and john...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>its not that am gsp fan just hate nick diaz ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iranian general says israel iron dome cannot d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tehran mon amour obama tried to establish ties...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet sentiment\n",
       "0  gas by my house hit am going to chapel hill on...  positive\n",
       "1  theo walcott is still shit watch rafa and john...  negative\n",
       "2  its not that am gsp fan just hate nick diaz ca...  negative\n",
       "3  iranian general says israel iron dome cannot d...  negative\n",
       "4  tehran mon amour obama tried to establish ties...   neutral"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    9155\n",
       "neutral     9074\n",
       "negative    3400\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to lematize the words\n",
    "def clean_tweet(tweet):\n",
    "    word_tokens= tweet.lower().split()\n",
    "    le=WordNetLemmatizer()\n",
    "    stop_words= set(stopwords.words(\"english\"))     \n",
    "    word_tokens= [le.lemmatize(w) for w in word_tokens if not w in stop_words]\n",
    "    \n",
    "    cleaned_tweet=\" \".join(word_tokens)\n",
    "    return cleaned_tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21629, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>gas by my house hit am going to chapel hill on...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>theo walcott is still shit watch rafa and john...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>its not that am gsp fan just hate nick diaz ca...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>iranian general says israel iron dome cannot d...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>tehran mon amour obama tried to establish ties...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet sentiment\n",
       "0  gas by my house hit am going to chapel hill on...  positive\n",
       "1  theo walcott is still shit watch rafa and john...  negative\n",
       "2  its not that am gsp fan just hate nick diaz ca...  negative\n",
       "3  iranian general says israel iron dome cannot d...  negative\n",
       "4  tehran mon amour obama tried to establish ties...   neutral"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21629, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>it will be some scene at the nyse and nasdaq s...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>snoop dogg son cordell broadus quits ucla foot...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>so everyone was so happy bc michael jackson ca...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>bulls season tips off wednesday night vs sacra...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>at no is jurassic world th installment of the ...</td>\n",
       "      <td>neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         clean_tweet sentiment\n",
       "0  it will be some scene at the nyse and nasdaq s...   neutral\n",
       "1  snoop dogg son cordell broadus quits ucla foot...   neutral\n",
       "2  so everyone was so happy bc michael jackson ca...  positive\n",
       "3  bulls season tips off wednesday night vs sacra...  negative\n",
       "4  at no is jurassic world th installment of the ...   neutral"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling rows\n",
    "df = df.sample(frac=1).reset_index(drop=True)\n",
    "print(df.shape)  # perfectly fine.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_tweet']=df['clean_tweet'].apply(clean_tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_directory = r\"../input/\"\n",
    "output_directory = r\"../output/\"\n",
    "\n",
    "if not os.path.exists(output_directory):\n",
    "    os.mkdir(output_directory)\n",
    "    \n",
    "figure_directory = \"../output/figures\"\n",
    "if not os.path.exists(figure_directory):\n",
    "    os.mkdir(figure_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0.],\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       ...,\n",
       "       [0., 1., 0.],\n",
       "       [0., 0., 1.],\n",
       "       [0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df['clean_tweet']\n",
    "Y = df['sentiment']\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "Y = label_encoder.fit_transform(Y)\n",
    "\n",
    "Y = to_categorical(Y)\n",
    "\n",
    "# Y = Y.reshape(-1, 1)\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28777, 150)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.15)\n",
    "\n",
    "max_words = len(set(\" \".join(X_train).split()))\n",
    "max_len = X_train.apply(lambda x: len(x)).max()\n",
    "\n",
    "# max_words = 1000\n",
    "# max_len = 150\n",
    "max_words, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_train_seq = sequence.pad_sequences(X_train_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Class Weights\n",
    "def get_weight(y):\n",
    "    class_weight_current =  cw.compute_class_weight('balanced', np.unique(y), y)\n",
    "    return class_weight_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = get_weight(Y_train.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rnn_model(num_class=2):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "    model.add(LSTM(256))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    if num_class>2:\n",
    "        model.add(Dense(num_class, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def get_cnn_model(num_class=2):   \n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "    \n",
    "    model.add(Conv1D(1024, 3, padding='valid', activation='relu', strides=1))\n",
    "    model.add(GlobalMaxPooling1D())\n",
    "    \n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    model.add(Dense(2048, activation='relu'))\n",
    "    \n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    if num_class>2:\n",
    "        model.add(Dense(num_class, activation='softmax'))\n",
    "    else:\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_performance(history=None, figure_directory=None, ylim_pad=[0, 0]):\n",
    "    xlabel = 'Epoch'\n",
    "    legends = ['Training', 'Validation']\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "\n",
    "    y1 = history.history['acc']\n",
    "    y2 = history.history['val_acc']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[0]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[0]\n",
    "\n",
    "\n",
    "    plt.subplot(121)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Accuracy\\n', fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Accuracy', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "\n",
    "    y1 = history.history['loss']\n",
    "    y2 = history.history['val_loss']\n",
    "\n",
    "    min_y = min(min(y1), min(y2))-ylim_pad[1]\n",
    "    max_y = max(max(y1), max(y2))+ylim_pad[1]\n",
    "\n",
    "\n",
    "    plt.subplot(122)\n",
    "\n",
    "    plt.plot(y1)\n",
    "    plt.plot(y2)\n",
    "\n",
    "    plt.title('Model Loss\\n', fontsize=17)\n",
    "    plt.xlabel(xlabel, fontsize=15)\n",
    "    plt.ylabel('Loss', fontsize=15)\n",
    "    plt.ylim(min_y, max_y)\n",
    "    plt.legend(legends, loc='upper left')\n",
    "    plt.grid()\n",
    "    if figure_directory:\n",
    "        plt.savefig(figure_directory+\"/history\")\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 150, 100)          2877700   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 256)               365568    \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3)                 1539      \n",
      "=================================================================\n",
      "Total params: 3,379,463\n",
      "Trainable params: 3,377,927\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "num_class = 3\n",
    "model = get_rnn_model(num_class=num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = 'categorical_crossentropy'\n",
    "# loss = 'binary_crossentropy'\n",
    "metrics = ['accuracy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting...\n",
      "\n",
      "\n",
      "\n",
      "Compliling Model ...\n",
      "\n",
      "Trainning Model ...\n",
      "\n",
      "Train on 14707 samples, validate on 3677 samples\n",
      "Epoch 1/20\n",
      "14707/14707 [==============================] - 127s 9ms/step - loss: 1.3241 - accuracy: 0.3932 - val_loss: 1.0315 - val_accuracy: 0.4115\n",
      "Epoch 2/20\n",
      "14707/14707 [==============================] - 130s 9ms/step - loss: 1.0812 - accuracy: 0.4131 - val_loss: 1.0298 - val_accuracy: 0.4115\n",
      "Epoch 3/20\n",
      "14707/14707 [==============================] - 123s 8ms/step - loss: 1.0728 - accuracy: 0.4202 - val_loss: 1.0271 - val_accuracy: 0.4267\n",
      "Epoch 4/20\n",
      "14707/14707 [==============================] - 137s 9ms/step - loss: 1.0702 - accuracy: 0.4218 - val_loss: 1.0249 - val_accuracy: 0.4267\n",
      "Epoch 5/20\n",
      "14707/14707 [==============================] - 137s 9ms/step - loss: 1.0608 - accuracy: 0.4218 - val_loss: 1.0241 - val_accuracy: 0.4137\n",
      "Epoch 6/20\n",
      "14707/14707 [==============================] - 138s 9ms/step - loss: 0.9351 - accuracy: 0.5610 - val_loss: 1.5695 - val_accuracy: 0.4210\n",
      "Epoch 7/20\n",
      "14707/14707 [==============================] - 133s 9ms/step - loss: 0.7555 - accuracy: 0.6782 - val_loss: 0.9495 - val_accuracy: 0.5619\n",
      "Epoch 8/20\n",
      "14707/14707 [==============================] - 136s 9ms/step - loss: 0.6390 - accuracy: 0.7337 - val_loss: 0.9691 - val_accuracy: 0.5711\n",
      "Epoch 9/20\n",
      "14707/14707 [==============================] - 136s 9ms/step - loss: 0.5342 - accuracy: 0.7809 - val_loss: 1.0135 - val_accuracy: 0.5779\n",
      "Epoch 10/20\n",
      "14707/14707 [==============================] - 132s 9ms/step - loss: 0.4050 - accuracy: 0.8478 - val_loss: 1.1105 - val_accuracy: 0.5817\n",
      "Epoch 11/20\n",
      "14707/14707 [==============================] - 131s 9ms/step - loss: 0.3105 - accuracy: 0.8956 - val_loss: 1.1791 - val_accuracy: 0.5755\n",
      "Epoch 12/20\n",
      "11472/14707 [======================>.......] - ETA: 27s - loss: 0.2350 - accuracy: 0.9263"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-5fd2f7605061>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mclass_weight\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     )\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3474\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3475\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 3476\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   3477\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3478\u001b[0m     output_structure = nest.pack_sequence_as(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Starting...\\n\")\n",
    "\n",
    "print(\"\\n\\nCompliling Model ...\\n\")\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate)\n",
    "# optimizer = Adam()\n",
    "\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
    "\n",
    "verbose = 1\n",
    "epochs = 20\n",
    "batch_size = 16\n",
    "validation_split = 0.2\n",
    "\n",
    "print(\"Trainning Model ...\\n\")\n",
    "\n",
    "history1 = model.fit(\n",
    "    X_train_seq,\n",
    "    Y_train,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    verbose=verbose,\n",
    "    validation_split=validation_split,\n",
    "    class_weight =class_weight\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'acc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-b6e30421139e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mplot_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhistory1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-39-0afc3bbe73ce>\u001b[0m in \u001b[0;36mplot_performance\u001b[0;34m(history, figure_directory, ylim_pad)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0my1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0my2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'val_acc'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'acc'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x360 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "#X_train_seq = sequence.pad_sequences(X_train_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = rev_frame.copy()\n",
    "test = test[['clean_tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[21630:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>down in the atlantic city ventnor margate ocea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>musical awareness great big beautiful tomorrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>on radio fm fri oct labour analyst shawn hatti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>kapan sih lo ngebuktiin jan ngomong doang susa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>excuse the connectivity of this live stream fr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5393</td>\n",
       "      <td>it has it is wednesday girls night out as band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5394</td>\n",
       "      <td>night college course sorted just have to enrol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5395</td>\n",
       "      <td>for the st time in years for your splendiferou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5396</td>\n",
       "      <td>nurses day may nursing the heart beat of the h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5397</td>\n",
       "      <td>we have minutes left until the nd episode of s...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5398 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            clean_tweet\n",
       "0     down in the atlantic city ventnor margate ocea...\n",
       "1     musical awareness great big beautiful tomorrow...\n",
       "2     on radio fm fri oct labour analyst shawn hatti...\n",
       "3     kapan sih lo ngebuktiin jan ngomong doang susa...\n",
       "4     excuse the connectivity of this live stream fr...\n",
       "...                                                 ...\n",
       "5393  it has it is wednesday girls night out as band...\n",
       "5394  night college course sorted just have to enrol...\n",
       "5395  for the st time in years for your splendiferou...\n",
       "5396  nurses day may nursing the heart beat of the h...\n",
       "5397  we have minutes left until the nd episode of s...\n",
       "\n",
       "[5398 rows x 1 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = test[['clean_tweet']]\n",
    "test = test.reset_index(drop=True)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_id = t_id[['tweet_id']]\n",
    "t_id = t_id.reset_index(drop=True)\n",
    "test_data = pd.concat([t_id, test], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>264238274963451904</td>\n",
       "      <td>atlantic city ventnor margate ocean city area ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>218775148495515649</td>\n",
       "      <td>musical awareness great big beautiful tomorrow...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>258965201766998017</td>\n",
       "      <td>radio fm fri oct labour analyst shawn hattingh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>262926411352903682</td>\n",
       "      <td>kapan sih lo ngebuktiin jan ngomong doang susa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>171874368908050432</td>\n",
       "      <td>excuse connectivity live stream baba amr many ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5393</td>\n",
       "      <td>210378118865756160</td>\n",
       "      <td>wednesday girl night band wilson phillips fill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5394</td>\n",
       "      <td>245177521304399872</td>\n",
       "      <td>night college course sorted enrole tomorrow fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5395</td>\n",
       "      <td>259280987089932288</td>\n",
       "      <td>st time year splendiferous entertainment art l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5396</td>\n",
       "      <td>201113950211940352</td>\n",
       "      <td>nurse day may nursing heart beat health</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5397</td>\n",
       "      <td>237999067286876160</td>\n",
       "      <td>minute left nd episode styled rock uknavi riha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5398 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id                                        clean_tweet\n",
       "0     264238274963451904  atlantic city ventnor margate ocean city area ...\n",
       "1     218775148495515649  musical awareness great big beautiful tomorrow...\n",
       "2     258965201766998017  radio fm fri oct labour analyst shawn hattingh...\n",
       "3     262926411352903682  kapan sih lo ngebuktiin jan ngomong doang susa...\n",
       "4     171874368908050432  excuse connectivity live stream baba amr many ...\n",
       "...                  ...                                                ...\n",
       "5393  210378118865756160  wednesday girl night band wilson phillips fill...\n",
       "5394  245177521304399872  night college course sorted enrole tomorrow fi...\n",
       "5395  259280987089932288  st time year splendiferous entertainment art l...\n",
       "5396  201113950211940352            nurse day may nursing heart beat health\n",
       "5397  237999067286876160  minute left nd episode styled rock uknavi riha...\n",
       "\n",
       "[5398 rows x 2 columns]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data['clean_tweet']=test_data['clean_tweet'].apply(clean_tweet)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_seq = tokenizer.texts_to_sequences(test_data['clean_tweet'])\n",
    "train_seq = sequence.pad_sequences(train_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model.predict_classes(train_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, ..., 1, 2, 2])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral     3198\n",
       "positive    2029\n",
       "negative     171\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def class_sentiment(prediction):\n",
    "    n = len(prediction)\n",
    "    sentiment = []\n",
    "    for i in range(n):\n",
    "        if(prediction[i] == 2):\n",
    "            sentiment.append('positive')\n",
    "        elif(prediction[i]==1):\n",
    "            sentiment.append('neutral')\n",
    "        else:\n",
    "            sentiment.append('negative')\n",
    "    return sentiment\n",
    "sentiment = class_sentiment(prediction)\n",
    "test_data['sentiment'] = sentiment\n",
    "test_data['sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data[['tweet_id','sentiment']]\n",
    "test_list = []\n",
    "heading = ['tweet_id', 'sentiment']\n",
    "test_list.append(heading)\n",
    "for i in range(len(test_data['tweet_id'])):\n",
    "    sub = []\n",
    "    sub.append(test_data['tweet_id'][i])\n",
    "    sub.append(test_data['sentiment'][i])\n",
    "    test_list.append(sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5399"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5398 entries, 0 to 5397\n",
      "Data columns (total 2 columns):\n",
      "tweet_id     5398 non-null int64\n",
      "sentiment    5398 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 84.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('rnn.csv', 'w', newline='') as fp:\n",
    "    a = csv.writer(fp, delimiter = \",\")\n",
    "    data = test_list\n",
    "    a.writerows(data)\n",
    "check = pd.read_csv(\"test_result.csv\")\n",
    "check.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
